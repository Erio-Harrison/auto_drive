![result](/asset/system_design.png)

# 分布式系统框架介绍

如引言中所说，我们的系统大致分为感知、规划和控制三个模块，而为了开发方便，我们往往会把这三个模块继续拆分成子模块。比如这里我把**感知模块**又拆成了**检测模块（ObstacleDetectionNode）**和**追踪模块（ObstacleTrackingNode）**，前者用于模拟初次检测障碍物，后者用来模拟追踪障碍物。

来自硬件检测的数据点中，会有很多无效数据点的存在。通过这种分离，我们可以在**检测模块**中做初步处理，然后在**追踪模块**中追踪实际有效的数据点。比如在我们目前系统的简易实现里，我们在**检测模块**里用简单的**K-means聚类**算法来过滤庞大的点云数据集，把有效的数据点发布给**追踪模块**,在**追踪模块**当中用**卡尔曼滤波器**来完成数据的预测和追踪。

当然，一切的数据来源是硬件，在这里，我们是通过**LidarSimulatorNode**来模拟来自硬件的数据。

**ObstacleTrackingNode**把追踪后的数据传给**路径规划模块(PathPlanningNode)**。**PathPlanningNode**根据接收到的障碍物数据，做出路径规划（我们暂时使用的是简单的**A*算法**），再把规划好的路径数据发送给**车辆控制模块（VehicleControlNode）**。**VehicleControlNode**会根据路径规划和目前的车辆状态，计算得到指令（加速、减速、转向等等）并更新车辆状态（位置、速度、加速度等等）。

所有的无人车辆都可以通过**网络通信模块（NetworkBridgeNode）** 接收来自 **VehicleControlNode** 的信息，然后和 **模拟中央服务器（MockServerNode）** 进行网络通信。

数据传递过程中涉及到的具体数据类型是**ROS2**的内置数据类型，后面代码实现的时候会具体介绍（当然，直接看架构图应该也可以看懂它们大致是干什么用的）。我们希望可视化看到这整个流程，所以**ObstacleDetectionNode**、**ObstacleTrackingNode**、**PathPlanningNode**、**VehicleControlNode**会把数据传给**AutoDriveVisualizerNode**，让我们可以看到自己的成果。

通过充分利用**ROS2**的**数据分发服务(Data distribution service，DDS)**，我们可以实现**分布式架构**。比如在计算机A上运行**ObstacleDetectionNode**，在计算机B上运行**ObstacleTrackingNode**，这两个节点将通过**DDS**的自动发现机制相互发现，并通过发布-订阅模式进行通信。

# lidar_simulator_node

正式开始代码部分了，假设你已经安装好了**ROS2**环境，然后我们来创建工作空间(就是建文件夹)：

```bash
mkdir -p write-you-an-autopilot-sys/src
```

```bash
cd src
```

所有功能模块在ROS2环境中都是通过专门的功能包来实现，要创建一个新的功能包，是用下面这个语法：

```bash
ros2 pkg create <新建功能包的名字> --build-type {cmake,ament_cmake,ament_python} --dependencies <依赖项>
```

**pkg**: 表示功能包相关的功能

**create**：表示创建功能包

**build-type**：表示新创建的功能包是C++还是Python的，如果使用C++或者C，这里就跟ament_cmake，如果使用Python，就跟ament_python

**package_name**：新建功能包的名字

我们来为`lidar_simulator_node`创建叫做`sensor_simulator`的功能包：

```bash
ros2 pkg create sensor_simulator --build-type ament_cmake --dependencies rclcpp
```

进入这个功能包的**src**，新建 **lidar_simulator_node.cpp**，然后就可以开始愉快的写C++代码啦！！



注意：我们需要安装一个编译代码的工具叫做 **colcon**:

```bash
sudo apt-get install python3-colcon-common-extensions
```